# my global config
global:
  scrape_interval:     15s # By default, scrape targets every 15 seconds.
  evaluation_interval: 15s # By default, scrape targets every 15 seconds.
  # scrape_timeout is set to the global default (10s).

  # Attach these labels to any time series or alerts when communicating with
  # external systems (federation, remote storage, Alertmanager).
  external_labels:
    monitor: 'my-project'

# Load and evaluate rules in this file every 'evaluation_interval' seconds.
rule_files:
  - "alert.rules"
  # - "first.rules"
  # - "second.rules"

# A scrape configuration containing exactly one endpoint to scrape:
scrape_configs:
  - job_name: 'app'
    scrape_interval: 5s
    metrics_path: '/actuator/prometheus'
    static_configs:
      # Note: Since we are using Docker to run Prometheus, it will be running in a Docker network that won't understand localhost/120.0.01, as you might expect. Since our app is running on localhost, and for the Docker container, localhost means its own network, we have to specify our system IP in place of it.
      #So instead of using locahost:8080, 192.168.2.8:8080 is used where 192.168.2.8 is my PC IP at the moment.
      - targets: ['192.168.1.12:8080']